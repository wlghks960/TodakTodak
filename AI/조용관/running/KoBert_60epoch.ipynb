{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8a13d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mcheckpoint\u001b[0m/  \u001b[01;34mdata\u001b[0m/  \u001b[01;34mmodel\u001b[0m/  README.md  requirements.txt  test.py  train.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21ccf732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "from kobert_transformers import get_tokenizer\n",
    "from model.classifier import KoBERTforSequenceClassfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a63bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee619f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = torch.load('../model/kobert/model_kobert_chatbot_60epoch.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350fdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'KoBertTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: 안녕\n",
      "Answer: 잠시 쉬어간다고 생각해보는 건 어때요?, index: 55, softmax_value: 0.7230838537216187\n",
      "--------------------------------------------------\n",
      "\n",
      "Question: 하루 잘 보냈어?\n",
      "Answer: 아, 그래요?, index: 90, softmax_value: 0.833807110786438\n",
      "--------------------------------------------------\n",
      "\n",
      "Question: 피곤하네\n",
      "Answer: 휴식을 취할 때가 된 것 아닐까요? 잠깐 쉬어가요~, index: 337, softmax_value: 0.8274337649345398\n",
      "--------------------------------------------------\n",
      "\n",
      "Question: 눈이 침침해\n",
      "Answer: 귀마개나 안대 등 숙면을 도와주는 물품을 사용해보는 건 어떨까요?, index: 300, softmax_value: 0.11854656040668488\n",
      "--------------------------------------------------\n",
      "\n",
      "Question: 눈물이 나와 ㅠㅠ\n",
      "Answer: 감수성이 풍부하다는 증거 같아요. 눈물이 많은 사람 중에 나쁜 사람은 없잖아요., index: 22, softmax_value: 0.9927871823310852\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def load_wellness_answer():\n",
    "    root_path = \".\"\n",
    "    category_path = f\"{root_path}/data/wellness_dialog_category.txt\"\n",
    "    answer_path = f\"{root_path}/data/wellness_dialog_answer.txt\"\n",
    "\n",
    "    c_f = open(category_path, 'r')\n",
    "    a_f = open(answer_path, 'r')\n",
    "\n",
    "    category_lines = c_f.readlines()\n",
    "    answer_lines = a_f.readlines()\n",
    "\n",
    "    category = {}\n",
    "    answer = {}\n",
    "    for line_num, line_data in enumerate(category_lines):\n",
    "        data = line_data.split('    ')\n",
    "        category[data[1][:-1]] = data[0]\n",
    "\n",
    "    for line_num, line_data in enumerate(answer_lines):\n",
    "        data = line_data.split('    ')\n",
    "        keys = answer.keys()\n",
    "        if (data[0] in keys):\n",
    "            answer[data[0]] += [data[1][:-1]]\n",
    "        else:\n",
    "            answer[data[0]] = [data[1][:-1]]\n",
    "\n",
    "    return category, answer\n",
    "\n",
    "\n",
    "def kobert_input(tokenizer, str, device=None, max_seq_len=512):\n",
    "    index_of_words = tokenizer.encode(str)\n",
    "    token_type_ids = [0] * len(index_of_words)\n",
    "    attention_mask = [1] * len(index_of_words)\n",
    "\n",
    "    # Padding Length\n",
    "    padding_length = max_seq_len - len(index_of_words)\n",
    "\n",
    "    # Zero Padding\n",
    "    index_of_words += [0] * padding_length\n",
    "    token_type_ids += [0] * padding_length\n",
    "    attention_mask += [0] * padding_length\n",
    "\n",
    "    data = {\n",
    "        'input_ids': torch.tensor([index_of_words]).to(device),\n",
    "        'token_type_ids': torch.tensor([token_type_ids]).to(device),\n",
    "        'attention_mask': torch.tensor([attention_mask]).to(device),\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root_path = \".\"\n",
    "    checkpoint_path = f\"{root_path}/checkpoint\"\n",
    "    save_ckpt_path = f\"{checkpoint_path}/kobert-wellness-text-classification.pth\"\n",
    "\n",
    "    # 답변과 카테고리 불러오기\n",
    "    category, answer = load_wellness_answer()\n",
    "\n",
    "    ctx = \"cuda:8\"\n",
    "    device = torch.device(ctx)\n",
    "\n",
    "    # 저장한 Checkpoint 불러오기\n",
    "    ##checkpoint = torch.load(save_ckpt_path, map_location=device)\n",
    "\n",
    "    ##model = KoBERTforSequenceClassfication()\n",
    "    ##model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    model = my_model\n",
    "    model.to(ctx)\n",
    "    model.eval()\n",
    "\n",
    "    tokenizer = get_tokenizer()\n",
    "\n",
    "    while 1:\n",
    "        sent = input('\\nQuestion: ')  # '요즘 기분이 우울한 느낌이에요'\n",
    "        data = kobert_input(tokenizer, sent, device, 512)\n",
    "\n",
    "        if '종료' in sent:\n",
    "            break\n",
    "\n",
    "        output = model(**data)\n",
    "\n",
    "        logit = output[0]\n",
    "        softmax_logit = torch.softmax(logit, dim=-1)\n",
    "        softmax_logit = softmax_logit.squeeze()\n",
    "\n",
    "        max_index = torch.argmax(softmax_logit).item()\n",
    "        max_index_value = softmax_logit[torch.argmax(softmax_logit)].item()\n",
    "\n",
    "        answer_list = answer[category[str(max_index)]]\n",
    "        answer_len = len(answer_list) - 1\n",
    "        answer_index = random.randint(0, answer_len)\n",
    "        print(f'Answer: {answer_list[answer_index]}, index: {max_index}, softmax_value: {max_index_value}')\n",
    "        print('-' * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
